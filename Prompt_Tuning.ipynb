{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z22CICbgUiR6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll simulate prompt tuning by:\n",
        "\n",
        "#****Freezing a base model.***\n",
        "\n",
        "#****Adding trainable prompt embeddings before the input sequence.***\n",
        "\n",
        "#****Training only the prompt using data loaded from a .csv.***"
      ],
      "metadata": {
        "id": "fX60SFDYUnvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Step 1: Load Dataset ---\n",
        "df = pd.read_csv(\"sentiment.csv\")  # Replace with your path\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S0RvMA74U2_m",
        "outputId": "0c73b366-99da-413e-fb94-df265dafdd3b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                text  label\n",
              "0         Awful plot      0\n",
              "1   Highly recommend      1\n",
              "2  This is fantastic      1\n",
              "3       Great acting      1\n",
              "4          Best ever      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b5e2783-d1f7-4dec-92bf-26894ff7d43a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Awful plot</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Highly recommend</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is fantastic</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Great acting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Best ever</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b5e2783-d1f7-4dec-92bf-26894ff7d43a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8b5e2783-d1f7-4dec-92bf-26894ff7d43a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8b5e2783-d1f7-4dec-92bf-26894ff7d43a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bcda19f2-fc44-42c3-90ab-77b2ada31634\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcda19f2-fc44-42c3-90ab-77b2ada31634')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bcda19f2-fc44-42c3-90ab-77b2ada31634 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Awful plot\",\n          \"Really bad\",\n          \"Waste of time\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text'].astype(str).tolist()\n",
        "labels = df['label'].astype(int).tolist()\n",
        "\n",
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6zMA2RvVqOc",
        "outputId": "667aa2df-f517-4a24-e5ef-1796f91f8286"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Awful plot',\n",
              " 'Highly recommend',\n",
              " 'This is fantastic',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'Terrible experience',\n",
              " 'Superb!',\n",
              " 'So boring',\n",
              " 'Amazing experience',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'So boring',\n",
              " 'Would not recommend',\n",
              " 'Thumbs up',\n",
              " 'I hate this',\n",
              " 'Best ever',\n",
              " 'Horrible acting',\n",
              " 'Awful plot',\n",
              " 'Amazing experience',\n",
              " 'Disappointing',\n",
              " 'Brilliant plot',\n",
              " 'Best ever',\n",
              " 'Waste of time',\n",
              " 'Horrible acting',\n",
              " 'Highly recommend',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'Thumbs down',\n",
              " 'Great acting',\n",
              " 'Would not recommend',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'Thumbs up',\n",
              " 'Absolutely loved it',\n",
              " 'So boring',\n",
              " 'Highly recommend',\n",
              " 'Awful plot',\n",
              " 'Absolutely loved it',\n",
              " 'Thumbs down',\n",
              " 'So boring',\n",
              " 'Would not recommend',\n",
              " 'Absolutely loved it',\n",
              " 'Disappointing',\n",
              " 'Amazing experience',\n",
              " 'I love this movie',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'I love this movie',\n",
              " 'I hate this',\n",
              " 'So boring',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'Waste of time',\n",
              " 'Terrible experience',\n",
              " 'Absolutely loved it',\n",
              " 'Absolutely loved it',\n",
              " 'Absolutely loved it',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Absolutely loved it',\n",
              " 'Really bad',\n",
              " 'Amazing experience',\n",
              " 'I love this movie',\n",
              " 'Superb!',\n",
              " 'Thumbs down',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Best ever',\n",
              " 'This is fantastic',\n",
              " 'Great acting',\n",
              " 'Great acting',\n",
              " 'Great acting',\n",
              " 'Horrible acting',\n",
              " 'Absolutely loved it',\n",
              " 'So boring',\n",
              " 'Horrible acting',\n",
              " 'Thumbs up',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'Terrible experience',\n",
              " 'Highly recommend',\n",
              " 'Really bad',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'This is fantastic',\n",
              " 'Great acting',\n",
              " 'Terrible experience',\n",
              " 'Disappointing',\n",
              " 'Amazing experience',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'Really bad',\n",
              " 'Great acting',\n",
              " 'I hate this',\n",
              " 'Disappointing',\n",
              " 'Great acting',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'Waste of time',\n",
              " 'So boring',\n",
              " 'Best ever',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Best ever',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Highly recommend',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Best ever',\n",
              " 'Great acting',\n",
              " 'Brilliant plot',\n",
              " 'Awful plot',\n",
              " 'Absolutely loved it',\n",
              " 'Horrible acting',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Terrible experience',\n",
              " 'Waste of time',\n",
              " 'Superb!',\n",
              " 'Great acting',\n",
              " 'Really bad',\n",
              " 'Awful plot',\n",
              " 'Awful plot',\n",
              " 'Great acting',\n",
              " 'Waste of time',\n",
              " 'Amazing experience',\n",
              " 'Superb!',\n",
              " 'Thumbs down',\n",
              " 'This is fantastic',\n",
              " 'I hate this',\n",
              " 'Thumbs up',\n",
              " 'Really bad',\n",
              " 'Would not recommend',\n",
              " 'Highly recommend',\n",
              " 'I love this movie',\n",
              " 'This is fantastic',\n",
              " 'Absolutely loved it',\n",
              " 'I hate this',\n",
              " 'Brilliant plot',\n",
              " 'Highly recommend',\n",
              " 'Superb!',\n",
              " 'I love this movie',\n",
              " 'So boring',\n",
              " 'Would not recommend',\n",
              " 'Horrible acting',\n",
              " 'Great acting',\n",
              " 'Amazing experience',\n",
              " 'Would not recommend',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'I hate this',\n",
              " 'I love this movie',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'This is fantastic',\n",
              " 'Awful plot',\n",
              " 'Thumbs down',\n",
              " 'Highly recommend',\n",
              " 'Brilliant plot',\n",
              " 'Terrible experience',\n",
              " 'Awful plot',\n",
              " 'Best ever',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Highly recommend',\n",
              " 'Waste of time',\n",
              " 'Brilliant plot',\n",
              " 'I love this movie',\n",
              " 'So boring',\n",
              " 'Horrible acting',\n",
              " 'This is fantastic',\n",
              " 'Best ever',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'Awful plot',\n",
              " 'Thumbs up',\n",
              " 'Thumbs down',\n",
              " 'Awful plot',\n",
              " 'I love this movie',\n",
              " 'Waste of time',\n",
              " 'I hate this',\n",
              " 'Waste of time',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Thumbs down',\n",
              " 'Really bad',\n",
              " 'This is fantastic',\n",
              " 'Would not recommend',\n",
              " 'Terrible experience',\n",
              " 'Really bad',\n",
              " 'I hate this',\n",
              " 'Thumbs up',\n",
              " 'Thumbs up',\n",
              " 'I hate this',\n",
              " 'So boring',\n",
              " 'I love this movie',\n",
              " 'Disappointing',\n",
              " 'Thumbs up',\n",
              " 'Terrible experience',\n",
              " 'This is fantastic',\n",
              " 'Waste of time',\n",
              " 'I hate this',\n",
              " 'Waste of time',\n",
              " 'Thumbs down',\n",
              " 'Awful plot',\n",
              " 'This is fantastic',\n",
              " 'Absolutely loved it',\n",
              " 'Terrible experience',\n",
              " 'Disappointing',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'Absolutely loved it',\n",
              " 'Thumbs down',\n",
              " 'Absolutely loved it',\n",
              " 'I love this movie',\n",
              " 'Disappointing',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'Brilliant plot',\n",
              " 'Terrible experience',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Brilliant plot',\n",
              " 'Absolutely loved it',\n",
              " 'Would not recommend',\n",
              " 'Brilliant plot',\n",
              " 'Awful plot',\n",
              " 'I hate this',\n",
              " 'Highly recommend',\n",
              " 'I hate this',\n",
              " 'Horrible acting',\n",
              " 'I love this movie',\n",
              " 'Thumbs up',\n",
              " 'So boring',\n",
              " 'Brilliant plot',\n",
              " 'Superb!',\n",
              " 'Disappointing',\n",
              " 'Amazing experience',\n",
              " 'Waste of time',\n",
              " 'Really bad',\n",
              " 'Highly recommend',\n",
              " 'Thumbs up',\n",
              " 'Really bad',\n",
              " 'Thumbs down',\n",
              " 'Highly recommend',\n",
              " 'Would not recommend',\n",
              " 'Awful plot',\n",
              " 'Horrible acting',\n",
              " 'Absolutely loved it',\n",
              " 'I hate this',\n",
              " 'I hate this',\n",
              " 'So boring',\n",
              " 'Superb!',\n",
              " 'Disappointing',\n",
              " 'This is fantastic',\n",
              " 'Waste of time',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'Awful plot',\n",
              " 'So boring',\n",
              " 'Really bad',\n",
              " 'Horrible acting',\n",
              " 'This is fantastic',\n",
              " 'Great acting',\n",
              " 'I hate this',\n",
              " 'Best ever',\n",
              " 'Thumbs up',\n",
              " 'Awful plot',\n",
              " 'I hate this',\n",
              " 'Would not recommend',\n",
              " 'So boring',\n",
              " 'This is fantastic',\n",
              " 'So boring',\n",
              " 'Amazing experience',\n",
              " 'Horrible acting',\n",
              " 'Highly recommend',\n",
              " 'Amazing experience',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'So boring',\n",
              " 'Horrible acting',\n",
              " 'Superb!',\n",
              " 'Thumbs up',\n",
              " 'Absolutely loved it',\n",
              " 'Best ever',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'Superb!',\n",
              " 'Would not recommend',\n",
              " 'Really bad',\n",
              " 'Awful plot',\n",
              " 'Thumbs down',\n",
              " 'Highly recommend',\n",
              " 'I love this movie',\n",
              " 'Really bad',\n",
              " 'I hate this',\n",
              " 'Horrible acting',\n",
              " 'Horrible acting',\n",
              " 'I hate this',\n",
              " 'Best ever',\n",
              " 'Waste of time',\n",
              " 'Thumbs down',\n",
              " 'Would not recommend',\n",
              " 'Terrible experience',\n",
              " 'Thumbs up',\n",
              " 'Really bad',\n",
              " 'Best ever',\n",
              " 'Horrible acting',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'Thumbs up',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Awful plot',\n",
              " 'I love this movie',\n",
              " 'Best ever',\n",
              " 'I love this movie',\n",
              " 'Really bad',\n",
              " 'I hate this',\n",
              " 'Highly recommend',\n",
              " 'Brilliant plot',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Terrible experience',\n",
              " 'Highly recommend',\n",
              " 'Great acting',\n",
              " 'This is fantastic',\n",
              " 'Best ever',\n",
              " 'Waste of time',\n",
              " 'Really bad',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Absolutely loved it',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Brilliant plot',\n",
              " 'Awful plot',\n",
              " 'Would not recommend',\n",
              " 'Disappointing',\n",
              " 'Great acting',\n",
              " 'Disappointing',\n",
              " 'Really bad',\n",
              " 'I hate this',\n",
              " 'This is fantastic',\n",
              " 'Highly recommend',\n",
              " 'Great acting',\n",
              " 'Awful plot',\n",
              " 'Highly recommend',\n",
              " 'I hate this',\n",
              " 'Superb!',\n",
              " 'Absolutely loved it',\n",
              " 'Really bad',\n",
              " 'Superb!',\n",
              " 'I love this movie',\n",
              " 'Amazing experience',\n",
              " 'Terrible experience',\n",
              " 'Disappointing',\n",
              " 'Terrible experience',\n",
              " 'Horrible acting',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'Awful plot',\n",
              " 'Would not recommend',\n",
              " 'Thumbs up',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'I hate this',\n",
              " 'Superb!',\n",
              " 'Absolutely loved it',\n",
              " 'This is fantastic',\n",
              " 'Amazing experience',\n",
              " 'Really bad',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'Great acting',\n",
              " 'Thumbs down',\n",
              " 'I hate this',\n",
              " 'Really bad',\n",
              " 'Waste of time',\n",
              " 'Brilliant plot',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Thumbs down',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'Awful plot',\n",
              " 'I hate this',\n",
              " 'Brilliant plot',\n",
              " 'Horrible acting',\n",
              " 'This is fantastic',\n",
              " 'Would not recommend',\n",
              " 'Waste of time',\n",
              " 'Amazing experience',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'Waste of time',\n",
              " 'Waste of time',\n",
              " 'Great acting',\n",
              " 'I hate this',\n",
              " 'Highly recommend',\n",
              " 'So boring',\n",
              " 'Horrible acting',\n",
              " 'Best ever',\n",
              " 'Great acting',\n",
              " 'Amazing experience',\n",
              " 'Thumbs up',\n",
              " 'Really bad',\n",
              " 'Terrible experience',\n",
              " 'Thumbs up',\n",
              " 'Would not recommend',\n",
              " 'So boring',\n",
              " 'I love this movie',\n",
              " 'So boring',\n",
              " 'Brilliant plot',\n",
              " 'I love this movie',\n",
              " 'This is fantastic',\n",
              " 'I love this movie',\n",
              " 'So boring',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Really bad',\n",
              " 'This is fantastic',\n",
              " 'I hate this',\n",
              " 'Thumbs up',\n",
              " 'Superb!',\n",
              " 'So boring',\n",
              " 'Would not recommend',\n",
              " 'Brilliant plot',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'Really bad',\n",
              " 'Horrible acting',\n",
              " 'Thumbs up',\n",
              " 'Terrible experience',\n",
              " 'Horrible acting',\n",
              " 'Waste of time',\n",
              " 'Great acting',\n",
              " 'Great acting',\n",
              " 'Waste of time',\n",
              " 'This is fantastic',\n",
              " 'Would not recommend',\n",
              " 'Horrible acting',\n",
              " 'This is fantastic',\n",
              " 'Absolutely loved it',\n",
              " 'Thumbs up',\n",
              " 'Disappointing',\n",
              " 'Waste of time',\n",
              " 'I love this movie',\n",
              " 'Really bad',\n",
              " 'Brilliant plot',\n",
              " 'Thumbs down',\n",
              " 'This is fantastic',\n",
              " 'Brilliant plot',\n",
              " 'Amazing experience',\n",
              " 'Thumbs down',\n",
              " 'Waste of time',\n",
              " 'Terrible experience',\n",
              " 'Horrible acting',\n",
              " 'Absolutely loved it',\n",
              " 'Would not recommend',\n",
              " 'Absolutely loved it',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Disappointing',\n",
              " 'Superb!',\n",
              " 'Amazing experience',\n",
              " 'I hate this',\n",
              " 'Would not recommend',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'Thumbs up',\n",
              " 'Terrible experience',\n",
              " 'Superb!',\n",
              " 'Absolutely loved it',\n",
              " 'Highly recommend',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'Absolutely loved it',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'Highly recommend',\n",
              " 'Absolutely loved it',\n",
              " 'Highly recommend',\n",
              " 'Thumbs down',\n",
              " 'Really bad',\n",
              " 'I hate this',\n",
              " 'Great acting',\n",
              " 'So boring',\n",
              " 'So boring',\n",
              " 'Thumbs up',\n",
              " 'Horrible acting',\n",
              " 'Horrible acting',\n",
              " 'Highly recommend',\n",
              " 'Thumbs down',\n",
              " 'Would not recommend',\n",
              " 'Thumbs up',\n",
              " 'I love this movie',\n",
              " 'Horrible acting',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'Amazing experience',\n",
              " 'Thumbs up',\n",
              " 'I hate this',\n",
              " 'I hate this',\n",
              " 'I love this movie',\n",
              " 'Amazing experience',\n",
              " 'Horrible acting',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Brilliant plot',\n",
              " 'Really bad',\n",
              " 'Best ever',\n",
              " 'Highly recommend',\n",
              " 'Waste of time',\n",
              " 'Great acting',\n",
              " 'Superb!',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'Brilliant plot',\n",
              " 'Amazing experience',\n",
              " 'This is fantastic',\n",
              " 'Awful plot',\n",
              " 'Amazing experience',\n",
              " 'Thumbs up',\n",
              " 'I love this movie',\n",
              " 'This is fantastic',\n",
              " 'Horrible acting',\n",
              " 'Best ever',\n",
              " 'Waste of time',\n",
              " 'So boring',\n",
              " 'I love this movie',\n",
              " 'Thumbs up',\n",
              " 'Thumbs up',\n",
              " 'Disappointing',\n",
              " 'Terrible experience',\n",
              " 'Really bad',\n",
              " 'I love this movie',\n",
              " 'Superb!',\n",
              " 'Amazing experience',\n",
              " 'Would not recommend',\n",
              " 'Superb!',\n",
              " 'I hate this',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'I love this movie',\n",
              " 'Superb!',\n",
              " 'Terrible experience',\n",
              " 'Really bad',\n",
              " 'This is fantastic',\n",
              " 'Highly recommend',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'Brilliant plot',\n",
              " 'Great acting',\n",
              " 'Amazing experience',\n",
              " 'Terrible experience',\n",
              " 'Waste of time',\n",
              " 'Awful plot',\n",
              " 'Awful plot',\n",
              " 'Awful plot',\n",
              " 'Brilliant plot',\n",
              " 'Disappointing',\n",
              " 'Disappointing',\n",
              " 'Thumbs up',\n",
              " 'Absolutely loved it',\n",
              " 'Waste of time',\n",
              " 'Highly recommend',\n",
              " 'Best ever',\n",
              " 'Absolutely loved it',\n",
              " 'Amazing experience',\n",
              " 'Disappointing',\n",
              " 'Waste of time',\n",
              " 'Best ever',\n",
              " 'Thumbs up',\n",
              " 'Superb!',\n",
              " 'Really bad',\n",
              " 'This is fantastic',\n",
              " 'Really bad',\n",
              " 'Amazing experience',\n",
              " 'I love this movie',\n",
              " 'Absolutely loved it',\n",
              " 'So boring',\n",
              " 'Great acting',\n",
              " 'This is fantastic',\n",
              " 'Horrible acting',\n",
              " 'Would not recommend',\n",
              " 'I love this movie',\n",
              " 'Disappointing',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'Awful plot',\n",
              " 'So boring',\n",
              " 'Absolutely loved it',\n",
              " 'Would not recommend',\n",
              " 'Thumbs down',\n",
              " 'Superb!',\n",
              " 'Great acting',\n",
              " 'Waste of time',\n",
              " 'Horrible acting',\n",
              " 'Best ever',\n",
              " 'Would not recommend',\n",
              " 'Awful plot',\n",
              " 'Disappointing',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'I hate this',\n",
              " 'Great acting',\n",
              " 'Awful plot',\n",
              " 'I love this movie',\n",
              " 'I hate this',\n",
              " 'Highly recommend',\n",
              " 'Thumbs up',\n",
              " 'Waste of time',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'Really bad',\n",
              " 'Horrible acting',\n",
              " 'Great acting',\n",
              " 'Amazing experience',\n",
              " 'Best ever',\n",
              " 'Terrible experience',\n",
              " 'Highly recommend',\n",
              " 'Thumbs down',\n",
              " 'I hate this',\n",
              " 'I hate this',\n",
              " 'Would not recommend',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'I hate this',\n",
              " 'I hate this',\n",
              " 'Really bad',\n",
              " 'Waste of time',\n",
              " 'Awful plot',\n",
              " 'Highly recommend',\n",
              " 'Highly recommend',\n",
              " 'Great acting',\n",
              " 'Horrible acting',\n",
              " 'Would not recommend',\n",
              " 'I hate this',\n",
              " 'Really bad',\n",
              " 'Best ever',\n",
              " 'Awful plot',\n",
              " 'This is fantastic',\n",
              " 'Terrible experience',\n",
              " 'Highly recommend',\n",
              " 'Best ever',\n",
              " 'Amazing experience',\n",
              " 'Thumbs up',\n",
              " 'Amazing experience',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'Would not recommend',\n",
              " 'Would not recommend',\n",
              " 'Disappointing',\n",
              " 'Great acting',\n",
              " 'Would not recommend',\n",
              " 'Really bad',\n",
              " 'Would not recommend',\n",
              " 'I love this movie',\n",
              " 'Would not recommend',\n",
              " 'Absolutely loved it',\n",
              " 'Highly recommend',\n",
              " 'Superb!',\n",
              " 'Thumbs down',\n",
              " 'Best ever',\n",
              " 'Highly recommend',\n",
              " 'Highly recommend',\n",
              " 'So boring',\n",
              " 'Highly recommend',\n",
              " 'Thumbs down',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'Absolutely loved it',\n",
              " 'Waste of time',\n",
              " 'This is fantastic',\n",
              " 'Brilliant plot',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'Thumbs up',\n",
              " 'Disappointing',\n",
              " 'Absolutely loved it',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'Best ever',\n",
              " 'Best ever',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'Horrible acting',\n",
              " 'Really bad',\n",
              " 'Great acting',\n",
              " 'Thumbs down',\n",
              " 'Disappointing',\n",
              " 'Terrible experience',\n",
              " 'Really bad',\n",
              " 'Great acting',\n",
              " 'Superb!',\n",
              " 'Great acting',\n",
              " 'Amazing experience',\n",
              " 'Absolutely loved it',\n",
              " 'Terrible experience',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Thumbs down',\n",
              " 'Great acting',\n",
              " 'Waste of time',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'Superb!',\n",
              " 'Terrible experience',\n",
              " 'Superb!',\n",
              " 'Terrible experience',\n",
              " 'I love this movie',\n",
              " 'Superb!',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Brilliant plot',\n",
              " 'Thumbs down',\n",
              " 'Horrible acting',\n",
              " 'Great acting',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Disappointing',\n",
              " 'I love this movie',\n",
              " 'I love this movie',\n",
              " 'Waste of time',\n",
              " 'So boring',\n",
              " 'Superb!',\n",
              " 'Brilliant plot',\n",
              " 'I hate this',\n",
              " 'Superb!',\n",
              " 'Awful plot',\n",
              " 'Awful plot',\n",
              " 'Would not recommend',\n",
              " 'I love this movie',\n",
              " 'Disappointing',\n",
              " 'I love this movie',\n",
              " 'Terrible experience',\n",
              " 'Thumbs down',\n",
              " 'Disappointing',\n",
              " 'Absolutely loved it',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Awful plot',\n",
              " 'Great acting',\n",
              " 'Thumbs down',\n",
              " 'So boring',\n",
              " 'I love this movie',\n",
              " 'Would not recommend',\n",
              " 'Amazing experience',\n",
              " 'So boring',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'This is fantastic',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'Waste of time',\n",
              " 'Thumbs up',\n",
              " 'Would not recommend',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Highly recommend',\n",
              " 'Brilliant plot',\n",
              " 'Highly recommend',\n",
              " 'Waste of time',\n",
              " 'Really bad',\n",
              " 'Disappointing',\n",
              " 'Superb!',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Highly recommend',\n",
              " 'Horrible acting',\n",
              " 'I love this movie',\n",
              " 'Really bad',\n",
              " 'Great acting',\n",
              " 'Superb!',\n",
              " 'Really bad',\n",
              " 'I love this movie',\n",
              " 'Disappointing',\n",
              " 'Terrible experience',\n",
              " 'Disappointing',\n",
              " 'Superb!',\n",
              " 'Disappointing',\n",
              " 'Great acting',\n",
              " 'So boring',\n",
              " 'This is fantastic',\n",
              " 'Really bad',\n",
              " 'I love this movie',\n",
              " 'Thumbs up',\n",
              " 'Superb!',\n",
              " 'This is fantastic',\n",
              " 'Absolutely loved it',\n",
              " 'Waste of time',\n",
              " 'Highly recommend',\n",
              " 'Horrible acting',\n",
              " 'Awful plot',\n",
              " 'Would not recommend',\n",
              " 'Superb!',\n",
              " 'Thumbs up',\n",
              " 'Great acting',\n",
              " 'Best ever',\n",
              " 'I love this movie',\n",
              " 'Absolutely loved it',\n",
              " 'Would not recommend',\n",
              " 'Waste of time',\n",
              " 'This is fantastic',\n",
              " 'Thumbs up',\n",
              " 'Horrible acting',\n",
              " 'Disappointing',\n",
              " 'Thumbs down',\n",
              " 'Great acting',\n",
              " 'Absolutely loved it',\n",
              " 'I hate this',\n",
              " 'Highly recommend',\n",
              " 'Great acting',\n",
              " 'This is fantastic',\n",
              " 'Horrible acting',\n",
              " 'I hate this',\n",
              " 'Absolutely loved it',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'Amazing experience',\n",
              " 'Awful plot',\n",
              " 'Thumbs down',\n",
              " 'Best ever',\n",
              " 'Best ever',\n",
              " 'Waste of time',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'Superb!',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'So boring',\n",
              " 'Awful plot',\n",
              " 'Amazing experience',\n",
              " 'Really bad',\n",
              " 'Thumbs up',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'Disappointing',\n",
              " 'Highly recommend',\n",
              " 'Terrible experience',\n",
              " 'Horrible acting',\n",
              " 'Highly recommend',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'Best ever',\n",
              " 'Disappointing',\n",
              " 'Best ever',\n",
              " 'Brilliant plot',\n",
              " 'Brilliant plot',\n",
              " 'Brilliant plot',\n",
              " 'I hate this',\n",
              " 'Superb!',\n",
              " 'So boring',\n",
              " 'Thumbs down',\n",
              " 'Waste of time',\n",
              " 'So boring',\n",
              " 'Awful plot',\n",
              " 'Would not recommend',\n",
              " 'This is fantastic',\n",
              " 'I hate this',\n",
              " 'Really bad',\n",
              " 'Would not recommend',\n",
              " 'Absolutely loved it',\n",
              " 'I love this movie',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'Would not recommend',\n",
              " 'Best ever',\n",
              " 'So boring',\n",
              " 'Waste of time',\n",
              " 'Terrible experience',\n",
              " 'I love this movie',\n",
              " 'Best ever',\n",
              " 'Horrible acting',\n",
              " 'I hate this',\n",
              " 'Amazing experience',\n",
              " 'Superb!',\n",
              " 'Best ever',\n",
              " 'This is fantastic',\n",
              " 'Best ever',\n",
              " 'I hate this',\n",
              " 'This is fantastic',\n",
              " 'Thumbs up',\n",
              " 'Waste of time',\n",
              " 'I hate this',\n",
              " 'Great acting',\n",
              " 'Great acting',\n",
              " 'Thumbs up',\n",
              " 'Disappointing',\n",
              " 'Terrible experience',\n",
              " 'Brilliant plot',\n",
              " 'Amazing experience',\n",
              " 'So boring',\n",
              " 'Thumbs up',\n",
              " 'Terrible experience',\n",
              " 'I hate this',\n",
              " 'Superb!',\n",
              " 'Brilliant plot',\n",
              " 'Really bad',\n",
              " 'Absolutely loved it',\n",
              " 'Thumbs down',\n",
              " 'This is fantastic',\n",
              " 'Brilliant plot',\n",
              " 'Highly recommend',\n",
              " 'Amazing experience',\n",
              " 'Waste of time',\n",
              " 'Disappointing',\n",
              " 'Horrible acting',\n",
              " 'Thumbs down',\n",
              " 'This is fantastic',\n",
              " 'Disappointing',\n",
              " 'Absolutely loved it',\n",
              " 'This is fantastic',\n",
              " 'I love this movie',\n",
              " 'Would not recommend',\n",
              " 'Thumbs up',\n",
              " 'Highly recommend',\n",
              " 'Awful plot',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'So boring',\n",
              " 'Thumbs up',\n",
              " 'Horrible acting',\n",
              " 'Best ever',\n",
              " 'Great acting',\n",
              " 'Awful plot',\n",
              " 'Best ever',\n",
              " 'Best ever',\n",
              " 'Thumbs down',\n",
              " 'Best ever',\n",
              " 'Superb!',\n",
              " 'Absolutely loved it',\n",
              " 'Superb!',\n",
              " 'Best ever',\n",
              " 'Terrible experience',\n",
              " 'Amazing experience',\n",
              " 'Brilliant plot',\n",
              " 'Waste of time',\n",
              " 'Amazing experience',\n",
              " 'I love this movie',\n",
              " 'I love this movie',\n",
              " 'Best ever',\n",
              " 'Awful plot',\n",
              " 'Superb!',\n",
              " 'Waste of time',\n",
              " 'Really bad',\n",
              " 'Would not recommend',\n",
              " 'Awful plot',\n",
              " 'Really bad',\n",
              " 'Superb!',\n",
              " 'I hate this',\n",
              " 'Thumbs down',\n",
              " 'Thumbs down',\n",
              " 'Best ever',\n",
              " 'Amazing experience',\n",
              " 'Disappointing',\n",
              " 'Would not recommend',\n",
              " 'Great acting',\n",
              " 'Highly recommend',\n",
              " 'Terrible experience',\n",
              " 'This is fantastic',\n",
              " 'Superb!',\n",
              " 'Thumbs up',\n",
              " 'Best ever',\n",
              " 'Absolutely loved it',\n",
              " 'Highly recommend',\n",
              " 'Really bad',\n",
              " 'Highly recommend',\n",
              " 'Superb!',\n",
              " 'Horrible acting',\n",
              " 'Amazing experience',\n",
              " 'Terrible experience',\n",
              " 'Best ever',\n",
              " 'Horrible acting',\n",
              " 'Waste of time',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "🧠 What is vocab_size?\n",
        "In natural language processing (NLP), vocab_size (short for vocabulary size) refers to:\n",
        "\n",
        "🔤 The total number of unique tokens (usually words or subwords) that your model is allowed to recognize or work with.\n",
        "\n",
        "🎯 In Practice (e.g., Keras Tokenizer):\n",
        "When you define:\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "You're telling Keras:\n",
        "\n",
        "“Keep only the 10,000 most frequent words from the training texts. Ignore the rest.”\n",
        "\n",
        "This means:\n",
        "\n",
        "The tokenizer builds a word-to-index mapping using the top 10,000 words. <--------------------\n",
        "\n",
        "Words outside this set get mapped to an “OOV” (out-of-vocabulary) token.\n",
        "\n",
        "💡 Why Limit the Vocabulary?\n",
        "Limiting vocab_size is important because:\n",
        "\n",
        "✅ Memory-efficient (smaller embedding matrices).\n",
        "\n",
        "🚀 Faster training and inference.\n",
        "\n",
        "📉 Reduces overfitting (especially on rare, noisy words).\n",
        "\n",
        "🔢 How It Affects the Embedding Layer\n",
        "If vocab_size = 10000 and embed_dim = 64, then:\n",
        "\n",
        "Embedding(input_dim=10000, output_dim=64)\n",
        "The embedding layer will create a matrix of shape (10000, 64):\n",
        "\n",
        "Each word index from 0 to 9999 will map to a 64-dimensional vector.\n",
        "\n",
        "⚠️ Note\n",
        "The actual number of words in your data might be more or less than vocab_size. It's just a cap on how many to use.\n",
        "\n"
      ],
      "metadata": {
        "id": "gADNuTkoZxNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Imagine this sentence:\n",
        "\n",
        "sentence = \"I love samosas\"\n",
        "We want to classify the sentiment of this sentence (positive or negative) using a neural network.\n",
        "\n",
        "🧾 Step 1: Tokenization (Word to Index)\n",
        "Let’s say we define this vocabulary:\n",
        "\n",
        "\n",
        "word_to_index = {\n",
        "    \"i\": 1,\n",
        "    \"love\": 2,\n",
        "    \"samosas\": 3,\n",
        "    \"<OOV>\": 0  # Out-of-vocabulary\n",
        "}\n",
        "Now the sentence \"I love samosas\" becomes:\n",
        "\n",
        "\n",
        "[1, 2, 3]\n",
        "\n",
        "🧱 Step 2: Embedding Layer\n",
        "We create an embedding layer like:\n",
        "\n",
        "\n",
        "Embedding(input_dim=4, output_dim=3)\n",
        "input_dim = 4 → we have 4 unique tokens (including OOV).\n",
        "\n",
        "output_dim = 3 → each word is represented as a 3D vector.\n",
        "\n",
        "Suppose the embedding matrix looks like:\n",
        "\n",
        "Word\tIndex\tEmbedding Vector\n",
        "<OOV>\t0\t[ 0.01, -0.02, 0.03]\n",
        "\"i\"\t1\t[-0.10, 0.20, 0.30]\n",
        "\"love\"\t2\t[ 0.50, 0.60, -0.40]\n",
        "\"samosas\"\t3\t[ 0.25, -0.30, 0.75]\n",
        "\n",
        "So, input [1, 2, 3] is converted to:\n",
        "\n",
        "[\n",
        " [-0.10,  0.20,  0.30],   # \"i\"\n",
        " [ 0.50,  0.60, -0.40],   # \"love\"\n",
        " [ 0.25, -0.30,  0.75]    # \"samosas\"\n",
        "]\n",
        "✅ You now have a 3×3 matrix (3 words × 3 features each).\n",
        "\n",
        "🧠 Why This Matters\n",
        "Words that mean similar things will be close together in vector space.\n",
        "\n",
        "Example: \"awesome\" and \"great\" may both map to [0.6, 0.8, -0.1]\n",
        "\n",
        "The model learns these embeddings from data during training!\n",
        "\n"
      ],
      "metadata": {
        "id": "P5baFTzcZPGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 20\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "🔍 Explanation:\n",
        "🔹 max_len = 20\n",
        "This defines the maximum number of tokens per input sequence.\n",
        "\n",
        "All sequences will be padded or truncated to exactly 20 tokens.\n",
        "\n",
        "🔹 vocab_size = 10000\n",
        "You're restricting the tokenizer to use the top 10,000 most frequent words.\n",
        "\n",
        "Any words not in this set get replaced with the <OOV> (Out Of Vocabulary) token.\n",
        "\n",
        "🔹 tokenizer = keras.preprocessing.text.Tokenizer(...)\n",
        "Creates a tokenizer that will:\n",
        "\n",
        "Index words (e.g., \"love\" → 53)\n",
        "\n",
        "Replace rare words with <OOV>\n",
        "\n",
        "🔹 tokenizer.fit_on_texts(texts)\n",
        "Learns the vocabulary from your list of strings (texts).\n",
        "\n",
        "Creates a word_index dictionary:\n",
        "\n",
        "\n",
        "{'<OOV>': 1, 'i': 2, 'love': 3, 'samosas': 4, ...}\n",
        "🔹 sequences = tokenizer.texts_to_sequences(texts)\n",
        "Converts each string into a list of integers (word indices).\n",
        "\n",
        "\n",
        "\"I love samosas\" → [2, 3, 4]\n",
        "🔹 padded = keras.preprocessing.sequence.pad_sequences(...)\n",
        "Pads each list to a uniform length of max_len (20).\n",
        "\n",
        "Padding is done with 0s at the end (padding='post').\n",
        "\n",
        "\n",
        "[2, 3, 4] → [2, 3, 4, 0, 0, 0, ..., 0]  # length = 20\n",
        "📊 Resulting padded shape:\n",
        "If texts contains 1000 sentences, you’ll get a matrix of shape:\n",
        "\n",
        "\n",
        "(1000, 20)\n",
        "Each row is a fixed-length representation of a sentence — ready to feed into an Embedding layer!\n",
        "\n",
        "🧠 Why is this crucial?\n",
        "Neural networks require fixed-length input.\n",
        "\n",
        "Word order is preserved in sequences (important for RNNs/LSTMs).\n",
        "\n",
        "Embedding layers work with integer input, not raw text.\n",
        "\n"
      ],
      "metadata": {
        "id": "sBcomxbXbRvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 2: Tokenize Text ---\n",
        "max_len = 20\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n"
      ],
      "metadata": {
        "id": "jkrD7qbgV-P4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded.shape  # Matrix shape is 2000 * 20  (2000 line of sentences and 20 max len.)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fODSDfpnbQd7",
        "outputId": "c5d10b7a-5efd-401b-b38b-5416eab88cce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKBb7P98cMEb",
        "outputId": "ad238c02-60de-49d2-ae4c-20a68bd51bc2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9,  0,  0, ...,  0,  0,  0],\n",
              "       [32, 33,  0, ...,  0,  0,  0],\n",
              "       [36, 37,  6, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 4, 16,  0, ...,  0,  0,  0],\n",
              "       [12,  7,  0, ...,  0,  0,  0],\n",
              "       [26, 27,  0, ...,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# --- Step 3: Build Base Model (Frozen) ---\n",
        "embed_dim = 64\n",
        "prompt_len = 5\n",
        "max_len = 20\n",
        "vocab_size = 10000 # Ensure vocab_size is defined\n",
        "\n",
        "def build_base_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Bidirectional(layers.LSTM(64))(inputs)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.trainable = False  # Freeze all layers\n",
        "    return model\n",
        "\n",
        "# --- Step 4: Prompt Tuning Model ---\n",
        "class PromptTuningModel(keras.Model):\n",
        "    def __init__(self, base_model, prompt_len, embed_dim, vocab_size):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.prompt_embeddings = tf.Variable(\n",
        "            tf.random.normal([prompt_len, embed_dim]), trainable=True, name=\"prompt_embeddings\" # trainable:True means prompt going to train.\n",
        "        )\n",
        "        # Remove the embedding layer from here as input is already embedded\n",
        "        self.embed = layers.Embedding(vocab_size, embed_dim, trainable=False)\n",
        "\n",
        "\n",
        "    def call(self, input_ids):\n",
        "        embedded = self.embed(input_ids)\n",
        "        batch_size = tf.shape(embedded)[0]\n",
        "        prompt = tf.tile(tf.expand_dims(self.prompt_embeddings, 0), [batch_size, 1, 1])\n",
        "        concat_input = tf.concat([prompt, embedded], axis=1)\n",
        "        return self.base_model(concat_input)\n",
        "\n",
        "# --- Step 5: Compile & Train ---\n",
        "# Define input shape for the base model after concatenation (max_len + prompt_len, embed_dim)\n",
        "base_model_input_shape = (max_len + prompt_len, embed_dim)\n",
        "base_model = build_base_model(base_model_input_shape)\n",
        "prompt_model = PromptTuningModel(base_model, prompt_len, embed_dim, vocab_size)\n",
        "\n",
        "prompt_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Ensure X_train and y_train are numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "prompt_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=16)\n",
        "\n",
        "# Optional: Save prompt embeddings\n",
        "tf.saved_model.save(prompt_model, \"saved_prompt_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKo8ro8SVqac",
        "outputId": "fb079dd2-6cca-4a14-b77b-79fa2065e182"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.4710 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 2/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4710 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 3/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4627 - loss: 0.6983 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 4/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4654 - loss: 0.6981 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 5/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4729 - loss: 0.6973 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 6/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4757 - loss: 0.6970 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 7/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4601 - loss: 0.6986 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 8/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4642 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 9/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4537 - loss: 0.6992 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 10/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4612 - loss: 0.6985 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 11/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4727 - loss: 0.6973 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 12/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4590 - loss: 0.6987 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 13/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4579 - loss: 0.6988 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 14/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4645 - loss: 0.6981 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 15/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4643 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 16/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4704 - loss: 0.6976 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 17/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4770 - loss: 0.6969 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 18/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4786 - loss: 0.6967 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 19/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4498 - loss: 0.6996 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 20/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4805 - loss: 0.6966 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 21/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4561 - loss: 0.6990 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 22/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4599 - loss: 0.6986 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 23/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4765 - loss: 0.6970 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 24/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4740 - loss: 0.6972 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 25/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4483 - loss: 0.6998 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 26/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4615 - loss: 0.6984 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 27/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4644 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 28/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4783 - loss: 0.6968 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 29/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4558 - loss: 0.6990 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 30/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4656 - loss: 0.6981 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 31/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4642 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 32/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4580 - loss: 0.6988 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 33/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4699 - loss: 0.6976 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 34/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4618 - loss: 0.6984 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 35/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4847 - loss: 0.6961 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 36/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4598 - loss: 0.6986 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 37/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4832 - loss: 0.6963 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 38/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4685 - loss: 0.6978 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 39/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4642 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 40/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4701 - loss: 0.6976 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 41/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4352 - loss: 0.7011 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 42/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4710 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 43/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4688 - loss: 0.6977 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 44/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4657 - loss: 0.6980 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 45/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4671 - loss: 0.6979 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 46/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4795 - loss: 0.6967 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 47/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4635 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 48/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4660 - loss: 0.6980 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 49/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4532 - loss: 0.6993 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 50/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4739 - loss: 0.6972 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 51/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4632 - loss: 0.6983 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 52/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4634 - loss: 0.6983 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 53/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4757 - loss: 0.6970 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 54/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4743 - loss: 0.6971 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 55/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4782 - loss: 0.6968 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 56/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4652 - loss: 0.6981 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 57/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4788 - loss: 0.6967 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 58/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4739 - loss: 0.6972 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 59/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4538 - loss: 0.6993 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 60/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4548 - loss: 0.6992 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 61/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4452 - loss: 0.7001 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 62/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4752 - loss: 0.6971 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 63/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4638 - loss: 0.6982 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 64/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4630 - loss: 0.6983 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 65/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4752 - loss: 0.6971 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 66/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.4674 - loss: 0.6978 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 67/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4631 - loss: 0.6983 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 68/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4540 - loss: 0.6992 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 69/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4563 - loss: 0.6990 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 70/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4720 - loss: 0.6974 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 71/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4916 - loss: 0.6954 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 72/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4783 - loss: 0.6968 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 73/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4551 - loss: 0.6991 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 74/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4709 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 75/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4784 - loss: 0.6968 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 76/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4796 - loss: 0.6967 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 77/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4482 - loss: 0.6998 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 78/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4668 - loss: 0.6979 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 79/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4541 - loss: 0.6992 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 80/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4482 - loss: 0.6998 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 81/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4740 - loss: 0.6972 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 82/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4550 - loss: 0.6991 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 83/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4758 - loss: 0.6970 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 84/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4722 - loss: 0.6974 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 85/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4757 - loss: 0.6970 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 86/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4710 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 87/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4741 - loss: 0.6972 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 88/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4570 - loss: 0.6989 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 89/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4684 - loss: 0.6978 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 90/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4486 - loss: 0.6998 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 91/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4624 - loss: 0.6984 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 92/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4674 - loss: 0.6979 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 93/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4617 - loss: 0.6984 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 94/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4754 - loss: 0.6971 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 95/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.4683 - loss: 0.6978 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 96/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4463 - loss: 0.7000 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 97/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4725 - loss: 0.6973 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 98/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4705 - loss: 0.6975 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 99/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4796 - loss: 0.6966 - val_accuracy: 0.4825 - val_loss: 0.6964\n",
            "Epoch 100/100\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4802 - loss: 0.6966 - val_accuracy: 0.4825 - val_loss: 0.6964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentences(prompt_model, tokenizer, sentences):\n",
        "    # Step 1: Tokenize and pad the input sentences\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "    # Step 2: Predict using the prompt model\n",
        "    predictions = prompt_model.predict(padded)\n",
        "\n",
        "    # Step 3: Display results\n",
        "    for sentence, pred in zip(sentences, predictions):\n",
        "        label = \"Positive\" if pred[0] > 0.5 else \"Negative\"\n",
        "        confidence = pred[0]\n",
        "        print(f\"Input: {sentence}\")\n",
        "        print(f\"Prediction: {label} (Confidence: {confidence:.2f})\\n\")\n"
      ],
      "metadata": {
        "id": "WPjc816fVqgx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example sentences\n",
        "test_sentences = [\n",
        "    \"I love this product\",\n",
        "    \"This is the worst experience ever\",\n",
        "    \"Absolutely fantastic!\",\n",
        "    \"I will never buy this again\"\n",
        "]\n",
        "\n",
        "# Run inference\n",
        "predict_sentences(prompt_model, tokenizer, test_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSNsC7ZPVqno",
        "outputId": "5b87ef0a-0668-42fb-f828-7ad74905bb67"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518ms/step\n",
            "Input: I love this product\n",
            "Prediction: Negative (Confidence: 0.47)\n",
            "\n",
            "Input: This is the worst experience ever\n",
            "Prediction: Negative (Confidence: 0.48)\n",
            "\n",
            "Input: Absolutely fantastic!\n",
            "Prediction: Negative (Confidence: 0.48)\n",
            "\n",
            "Input: I will never buy this again\n",
            "Prediction: Negative (Confidence: 0.47)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1uWjvQMyVqrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Step 1: Load Dataset ---\n",
        "df = pd.read_csv(\"sentiment_10000.csv\")\n",
        "texts = df['text'].astype(str).tolist()\n",
        "labels = df['label'].astype(int).tolist()\n",
        "\n",
        "# --- Step 2: Tokenize Text ---\n",
        "max_len = 20\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "# --- Step 3: Train-Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded, labels, test_size=0.2, random_state=42)\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# --- Step 4: Base Model ---\n",
        "embed_dim = 64\n",
        "prompt_len = 5\n",
        "\n",
        "def build_base_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False, dropout=0.2))(inputs)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = keras.Model(inputs, outputs)\n",
        "    model.trainable = True  # Set to True if you want to unfreeze LSTM for better performance\n",
        "    return model\n",
        "\n",
        "# --- Step 5: Prompt Tuning Model ---\n",
        "class PromptTuningModel(keras.Model):\n",
        "    def __init__(self, base_model, prompt_len, embed_dim, vocab_size):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.prompt_embeddings = tf.Variable(\n",
        "            tf.random.normal([prompt_len, embed_dim]), trainable=True, name=\"prompt_embeddings\"\n",
        "        )\n",
        "        self.embed = layers.Embedding(vocab_size, embed_dim, trainable=True)  # Set trainable=True for better results\n",
        "\n",
        "    def call(self, input_ids):\n",
        "        embedded = self.embed(input_ids)\n",
        "        batch_size = tf.shape(embedded)[0]\n",
        "        prompt = tf.tile(tf.expand_dims(self.prompt_embeddings, 0), [batch_size, 1, 1])\n",
        "        concat_input = tf.concat([prompt, embedded], axis=1)\n",
        "        return self.base_model(concat_input)\n",
        "\n",
        "# --- Step 6: Compile and Train ---\n",
        "base_model_input_shape = (max_len + prompt_len, embed_dim)\n",
        "base_model = build_base_model(base_model_input_shape)\n",
        "prompt_model = PromptTuningModel(base_model, prompt_len, embed_dim, vocab_size)\n",
        "\n",
        "prompt_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "prompt_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, batch_size=32)\n",
        "\n",
        "# --- Step 7: Inference Function ---\n",
        "def predict_sentences(prompt_model, tokenizer, sentences):\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    padded = keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "    predictions = prompt_model.predict(padded)\n",
        "    for sentence, pred in zip(sentences, predictions):\n",
        "        label = \"Positive\" if pred[0] > 0.5 else \"Negative\"\n",
        "        print(f\"Input: {sentence}\")\n",
        "        print(f\"Prediction: {label} (Confidence: {pred[0]:.2f})\\n\")\n",
        "\n",
        "# --- Example Inference ---\n",
        "test_sentences = [\n",
        "    \"I love this product\",\n",
        "    \"Worst experience ever\",\n",
        "    \"Perfect in every way\",\n",
        "    \"Would not recommend\"\n",
        "]\n",
        "predict_sentences(prompt_model, tokenizer, test_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzs3TpASVqsQ",
        "outputId": "09a871de-2f84-4b29-bcab-366410e99175"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - accuracy: 0.7689 - loss: 0.3933 - val_accuracy: 1.0000 - val_loss: 6.0606e-05\n",
            "Epoch 2/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 4.4268e-05 - val_accuracy: 1.0000 - val_loss: 1.7822e-05\n",
            "Epoch 3/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4709e-05 - val_accuracy: 1.0000 - val_loss: 8.2456e-06\n",
            "Epoch 4/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 7.1523e-06 - val_accuracy: 1.0000 - val_loss: 4.7272e-06\n",
            "Epoch 5/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 4.2320e-06 - val_accuracy: 1.0000 - val_loss: 3.0470e-06\n",
            "Epoch 6/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 2.7672e-06 - val_accuracy: 1.0000 - val_loss: 2.1021e-06\n",
            "Epoch 7/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.9526e-06 - val_accuracy: 1.0000 - val_loss: 1.5220e-06\n",
            "Epoch 8/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.4091e-06 - val_accuracy: 1.0000 - val_loss: 1.1414e-06\n",
            "Epoch 9/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.0638e-06 - val_accuracy: 1.0000 - val_loss: 8.7769e-07\n",
            "Epoch 10/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.1819e-07 - val_accuracy: 1.0000 - val_loss: 6.8867e-07\n",
            "Epoch 11/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 6.5517e-07 - val_accuracy: 1.0000 - val_loss: 5.4909e-07\n",
            "Epoch 12/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 5.1305e-07 - val_accuracy: 1.0000 - val_loss: 4.4326e-07\n",
            "Epoch 13/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 4.2028e-07 - val_accuracy: 1.0000 - val_loss: 3.6167e-07\n",
            "Epoch 14/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 3.4402e-07 - val_accuracy: 1.0000 - val_loss: 2.9760e-07\n",
            "Epoch 15/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 2.8241e-07 - val_accuracy: 1.0000 - val_loss: 2.4693e-07\n",
            "Epoch 16/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 2.3235e-07 - val_accuracy: 1.0000 - val_loss: 2.0587e-07\n",
            "Epoch 17/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.9729e-07 - val_accuracy: 1.0000 - val_loss: 1.7282e-07\n",
            "Epoch 18/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.6455e-07 - val_accuracy: 1.0000 - val_loss: 1.4577e-07\n",
            "Epoch 19/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 1.4016e-07 - val_accuracy: 1.0000 - val_loss: 1.2318e-07\n",
            "Epoch 20/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 1.1717e-07 - val_accuracy: 1.0000 - val_loss: 1.0468e-07\n",
            "Epoch 21/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 1.0146e-07 - val_accuracy: 1.0000 - val_loss: 8.9394e-08\n",
            "Epoch 22/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 8.5624e-08 - val_accuracy: 1.0000 - val_loss: 7.6120e-08\n",
            "Epoch 23/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 7.3691e-08 - val_accuracy: 1.0000 - val_loss: 6.4954e-08\n",
            "Epoch 24/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 6.2342e-08 - val_accuracy: 1.0000 - val_loss: 5.6203e-08\n",
            "Epoch 25/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 5.4399e-08 - val_accuracy: 1.0000 - val_loss: 4.8781e-08\n",
            "Epoch 26/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 4.7507e-08 - val_accuracy: 1.0000 - val_loss: 4.2537e-08\n",
            "Epoch 27/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 4.1579e-08 - val_accuracy: 1.0000 - val_loss: 3.6617e-08\n",
            "Epoch 28/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 3.5010e-08 - val_accuracy: 1.0000 - val_loss: 3.0981e-08\n",
            "Epoch 29/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.9230e-08 - val_accuracy: 1.0000 - val_loss: 2.5717e-08\n",
            "Epoch 30/30\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 2.4252e-08 - val_accuracy: 1.0000 - val_loss: 2.1933e-08\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
            "Input: I love this product\n",
            "Prediction: Positive (Confidence: 1.00)\n",
            "\n",
            "Input: Worst experience ever\n",
            "Prediction: Negative (Confidence: 0.00)\n",
            "\n",
            "Input: Perfect in every way\n",
            "Prediction: Positive (Confidence: 1.00)\n",
            "\n",
            "Input: Would not recommend\n",
            "Prediction: Negative (Confidence: 0.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example Inference ---\n",
        "test_sentences = [\n",
        "    \"I hacked the website but it help company to know volunabilities\",\n",
        "    \"good thing to do but bad thing may come in life\",\n",
        "    \"love and fight are life\",\n",
        "    \"Would not recommended but need of it\"\n",
        "]\n",
        "predict_sentences(prompt_model, tokenizer, test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FT_v-yGjYXo",
        "outputId": "e52503ad-d559-4b3b-f346-baed309e47ab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
            "Input: I hacked the website but it help company to know volunabilities\n",
            "Prediction: Negative (Confidence: 0.00)\n",
            "\n",
            "Input: good thing to do but bad thing may come in life\n",
            "Prediction: Negative (Confidence: 0.00)\n",
            "\n",
            "Input: love and fight are life\n",
            "Prediction: Positive (Confidence: 1.00)\n",
            "\n",
            "Input: Would not recommended but need of it\n",
            "Prediction: Negative (Confidence: 0.00)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}